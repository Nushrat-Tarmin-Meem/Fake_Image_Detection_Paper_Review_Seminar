@ARTICLE{1,
  author={Deng, Xin and Zhao, Bihe and Guan, Zhenyu and Xu, Mai},
  journal={IEEE Signal Processing Letters}, 
  title={New Finding and Unified Framework for Fake Image Detection}, 
  year={2023},
  volume={30},
  number={},
  pages={90-94},
  keywords={Faces;Feature extraction;Forgery;Generative adversarial networks;Probability density function;Noise reduction;Security;Fake face detection;generative neural network;non-local similarity},
  doi={10.1109/LSP.2023.3243770}}

@INPROCEEDINGS {2,
author = {U. Ojha and Y. Li and Y. Lee},
booktitle = {2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
title = {Towards Universal Fake Image Detectors that Generalize Across Generative Models},
year = {2023},
volume = {},
issn = {},
pages = {24480-24489},
abstract = {With generative models proliferating at a rapid rate, there is a growing need for general purpose fake image detectors. In this work, we first show that the existing paradigm, which consists of training a deep network for real-vs-fake classification, fails to detect fake images from newer breeds of generative models when trained to detect GAN fake images. Upon analysis, we find that the resulting classifier is asymmetrically tuned to detect patterns that make an image fake. The real class becomes a ‘sink’ class holding anything that is not fake, including generated images from models not accessible during training. Building upon this discovery, we propose to perform real-vs-fake classification without learning; i.e., using a feature space not explicitly trained to distinguish real from fake images. We use nearest neighbor and linear probing as instantiations of this idea. When given access to the feature space of a large pretrained vision-language model, the very simple baseline of nearest neighbor classification has surprisingly good generalization ability in detecting fake images from a wide variety of generative models; e.g., it improves upon the SoTA [50] by +15.07 mAP and +25.90% acc when tested on unseen diffusion and autoregressive models. Our code, models, and data can be found at https://github.com/Yuheng-Li/UniversalFakeDetect},
keywords = {training;computer vision;codes;computational modeling;buildings;detectors;generative adversarial networks},
doi = {10.1109/CVPR52729.2023.02345},
url = {https://doi.ieeecomputersociety.org/10.1109/CVPR52729.2023.02345},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {jun}
}

@INPROCEEDINGS{3,
  author={Tanaka, Miki and Kiya, Hitoshi},
  booktitle={2021 IEEE 3rd Global Conference on Life Sciences and Technologies (LifeTech)}, 
  title={Fake-image detection with Robust Hashing}, 
  year={2021},
  volume={},
  number={},
  pages={40-43},
  keywords={Image coding;Conferences;Transform coding;Life sciences;Gallium nitride;fake images;GAN},
  doi={10.1109/LifeTech52111.2021.9391842}}

@INPROCEEDINGS{4,
  author={Karras, Tero and Laine, Samuli and Aila, Timo},
  booktitle={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={A Style-Based Generator Architecture for Generative Adversarial Networks}, 
  year={2019},
  volume={},
  number={},
  pages={4396-4405},
  keywords={Deep Learning;Image and Video Synthesis; Representation Learning},
  doi={10.1109/CVPR.2019.00453}}

@INPROCEEDINGS{5,
  author={Thies, Justus and Zollhöfer, Michael and Stamminger, Marc and Theobalt, Christian and Nießner, Matthias},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Face2Face: Real-Time Face Capture and Reenactment of RGB Videos}, 
  year={2016},
  volume={},
  number={},
  pages={2387-2395},
  keywords={Videos;Face;Real-time systems;Mouth;Shape;Target tracking;Lighting},
  doi={10.1109/CVPR.2016.262}}

@INPROCEEDINGS{6,
  author={Wang, Chengrui and Deng, Weihong},
  booktitle={2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Representative Forgery Mining for Fake Face Detection}, 
  year={2021},
  volume={},
  number={},
  pages={14918-14927},
  keywords={Codes;Face recognition;Refining;Training data;Data visualization;Detectors;Forgery},
  doi={10.1109/CVPR46437.2021.01468}}

@article{7,
  title={Image Denoising Using Quadtree-Based Nonlocal Means With Locally Adaptive Principal Component Analysis},
  author={Chenglin Zuo and Ljubomir Jovanov and Bart Goossens and Hi{\^e}p Quang Luong and Wilfried Philips and Yu Liu and Maojun Zhang},
  journal={IEEE Signal Processing Letters},
  year={2016},
  volume={23},
  pages={434-438},
  url={https://api.semanticscholar.org/CorpusID:206441296}
}

@INPROCEEDINGS{8,
  author={Agarwal, Shruti and Farid, Hany},
  booktitle={2017 IEEE Workshop on Information Forensics and Security (WIFS)}, 
  title={Photo forensics from JPEG dimples}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  keywords={Transform coding;Cameras;Discrete cosine transforms;Forensics;Image coding;Frequency-domain analysis;Quantization (signal);Image forensics;JPEG compression},
  doi={10.1109/WIFS.2017.8267641}}

@INPROCEEDINGS{9,
  author={Choi, Yunjey and Choi, Minje and Kim, Munyoung and Ha, Jung-Woo and Kim, Sunghun and Choo, Jaegul},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 
  title={StarGAN: Unified Generative Adversarial Networks for Multi-domain Image-to-Image Translation}, 
  year={2018},
  volume={},
  number={},
  pages={8789-8797},
  abstract={Recent studies have shown remarkable success in image-to-image translation for two domains. However, existing approaches have limited scalability and robustness in handling more than two domains, since different models should be built independently for every pair of image domains. To address this limitation, we propose StarGAN, a novel and scalable approach that can perform image-to-image translations for multiple domains using only a single model. Such a unified model architecture of StarGAN allows simultaneous training of multiple datasets with different domains within a single network. This leads to StarGAN's superior quality of translated images compared to existing models as well as the novel capability of flexibly translating an input image to any desired target domain. We empirically demonstrate the effectiveness of our approach on a facial attribute transfer and a facial expression synthesis tasks.},
  keywords={Generators;Task analysis;Training;Image reconstruction;Generative adversarial networks;Hair;Gallium nitride},
  doi={10.1109/CVPR.2018.00916},
  ISSN={2575-7075},
  month={June},}

@article{10,
  title={Detection of GAN-Generated Fake Images over Social Networks},
  author={Francesco Marra and Diego Gragnaniello and Davide Cozzolino and Luisa Verdoliva},
  journal={2018 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)},
  year={2018},
  pages={384-389},
  url={https://api.semanticscholar.org/CorpusID:49539556}
}

@article{11,
  title={Semantic Image Synthesis With Spatially-Adaptive Normalization},
  author={Taesung Park and Ming-Yu Liu and Ting-Chun Wang and Jun-Yan Zhu},
  journal={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2019},
  pages={2332-2341},
  url={https://api.semanticscholar.org/CorpusID:81981856}
}

@INPROCEEDINGS{12,
  author={Rao, Yuan and Ni, Jiangqun},
  booktitle={2016 IEEE International Workshop on Information Forensics and Security (WIFS)}, 
  title={A deep learning approach to detection of splicing and copy-move forgeries in images}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  keywords={Feature extraction;Convolution;Splicing;Forgery;Support vector machines;Kernel;Machine learning},
  doi={10.1109/WIFS.2016.7823911}}

@article{13,
  title={Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks},
  author={Jun-Yan Zhu and Taesung Park and Phillip Isola and Alexei A. Efros},
  journal={2017 IEEE International Conference on Computer Vision (ICCV)},
  year={2017},
  pages={2242-2251},
  url={https://api.semanticscholar.org/CorpusID:206770979}
}

@INPROCEEDINGS{14,
  author={Kinoshita, Yuma and Kiya, Hitoshi},
  booktitle={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Fixed Smooth Convolutional Layer for Avoiding Checkerboard Artifacts in CNNS}, 
  year={2020},
  volume={},
  number={},
  pages={3712-3716},
  keywords={Convolution;Conferences;Network architecture;Generative adversarial networks;Convolutional neural networks;Kernel;Speech processing;Checkerboard artifacts;Convolutional neural networks;Deep learning;Fixed convolutional layers;Generative adversarial networks},
  doi={10.1109/ICASSP40776.2020.9054096}}

@INPROCEEDINGS{15,
  author={Zhang, Xu and Karaman, Svebor and Chang, Shih-Fu},
  booktitle={2019 IEEE International Workshop on Information Forensics and Security (WIFS)}, 
  title={Detecting and Simulating Artifacts in GAN Fake Images}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  keywords={Gallium nitride;Generative adversarial networks;Convolution;Pipelines;Generators;Training;Tensors},
  doi={10.1109/WIFS47025.2019.9035107}}

@article{16,
  title={LSUN: Construction of a Large-scale Image Dataset using Deep Learning with Humans in the Loop},
  author={Fisher Yu and Yinda Zhang and Shuran Song and Ari Seff and Jianxiong Xiao},
  journal={ArXiv},
  year={2015},
  volume={abs/1506.03365},
  url={https://api.semanticscholar.org/CorpusID:8317437}
}

@article{17,
  title={Synergistic effect of well-defined dual sites boosting the oxygen reduction reaction},
  author={Jing Wang and W. Liu and Gan Luo and Zhijun Li and Chao Zhao and Haoran Zhang and Mengzhao Zhu and Qian Xu and Xiaoqian Wang and Changming Zhao and Yunteng Qu and Zheng Kun Yang and Tao Yao and Yafei Li and Yue Lin and Yuen Wu and Yadong Li},
  journal={Energy and Environmental Science},
  year={2018},
  volume={11},
  pages={3375-3379},
  url={https://api.semanticscholar.org/CorpusID:106142059}
}

@INPROCEEDINGS{18,
  author={Zhang, Xu and Karaman, Svebor and Chang, Shih-Fu},
  booktitle={2019 IEEE International Workshop on Information Forensics and Security (WIFS)}, 
  title={Detecting and Simulating Artifacts in GAN Fake Images}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  keywords={Gallium nitride;Generative adversarial networks;Convolution;Pipelines;Generators;Training;Tensors},
  doi={10.1109/WIFS47025.2019.9035107}}
